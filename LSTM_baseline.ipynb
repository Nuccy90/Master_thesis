{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_baseline.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nuccy90/Master_thesis/blob/master/LSTM_baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "tSfnXhMPGqU-",
        "colab_type": "code",
        "outputId": "9902bd02-f37b-40de-c559-9406d41aeb5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import itertools\n",
        "import io\n",
        "import nltk\n",
        "import pickle\n",
        "from tensorflow import keras\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dropout, Dense\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "zatLzk6LbDwB",
        "colab_type": "code",
        "outputId": "cddefe91-7d31-485d-cf99-d07268ce7033",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "f5c049c7-5ac3-4bf6-bc87-5c1483ec2579",
        "id": "h9mGeE6rs6Lq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "M8jL3EpfGxq7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def read_data(name):\n",
        "    \n",
        "    df = pd.read_csv(name)\n",
        "    df['Text'] = df['Text'].fillna(\"  \")\n",
        "    df['Title'] = df['Title'].fillna(\"  \")\n",
        "    df = df[(df[\"Text\"] != \"  \") | (df[\"Title\"]!= \"  \")]\n",
        "    docs = df['Title'] + df['Text']\n",
        "    Y = df[\"Diagnosis\"].values\n",
        "    \n",
        "    return df, docs, Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B_8oJlSNG-9f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cleanText(text):\n",
        "    \n",
        "    sw = stopwords.words('english')[35:]\n",
        "    text = re.sub(r'\\|\\|\\|', r' ', text) \n",
        "    text = re.sub(r'http\\S+', r'<URL>', text)\n",
        "    text = re.sub(r'\\d{6,}', r'<NUM>', text)\n",
        "    text = text.lower()\n",
        "    text = ' '.join(word for word in text.split() if not word in sw)\n",
        "    \n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ox0vG4iZHDiT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sort_by_date(df):\n",
        "\n",
        "    di = {}\n",
        "    for index, row in df.iterrows():\n",
        "\n",
        "        sub_id = row[\"Subject\"]\n",
        "        diagnosis = row[\"Diagnosis\"]\n",
        "        if sub_id in di:\n",
        "            di[sub_id][1].append(row[\"Text\"]+row[\"Title\"])\n",
        "            di[sub_id][2].append(row[\"Date\"])\n",
        "        else:\n",
        "            di[sub_id] = [diagnosis,[row[\"Text\"]+row[\"Title\"]], [row[\"Date\"]]]\n",
        "\n",
        "    for key in di:\n",
        "        list_of_datetimes = [datetime.strptime(x, ' %Y-%m-%d %H:%M:%S ') for x in di[key][2]]\n",
        "\n",
        "        lists = sorted(zip(*[list_of_datetimes, di[key][1]]))\n",
        "        dates, texts = list(zip(*lists))\n",
        "\n",
        "        di[key][1] = texts\n",
        "        di[key][2] = dates\n",
        "        \n",
        "    return di"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wNHZRTHgHJy0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict_texts(di, model, tokenizer):\n",
        "    print(\"Starting prediction...\")\n",
        "    pred_dict = {}\n",
        "    \n",
        "    def predict_scores(sub_id, texts, model = model, tokenizer = tokenizer, pred_dict = pred_dict):\n",
        "    \n",
        "        #add score to dictionary\n",
        "        x_texts = tokenizer.texts_to_sequences(texts)\n",
        "        x_texts = sequence.pad_sequences(x_texts, maxlen=100)\n",
        "        scores = model.predict(x_texts)\n",
        "        pred_dict[sub_id] = scores\n",
        "            \n",
        "        return pred_dict\n",
        "    \n",
        "    for sub_id in di:\n",
        "        texts = di[sub_id][1]\n",
        "        pred_dict = predict_scores(sub_id, texts)\n",
        "    \n",
        "    print(\"Prediction done!\")\n",
        "    return pred_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1Xy7-0jJHO7x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_train_vectors(pred_dict, di):\n",
        "    \n",
        "    x_train = []\n",
        "    y_train = []\n",
        "\n",
        "    for i in range(1,2000):\n",
        "        for sub_id in pred_dict:\n",
        "        \n",
        "            if i >= len(pred_dict[sub_id]):\n",
        "                pass\n",
        "            else:\n",
        "                seen = pred_dict[sub_id][:i]\n",
        "                avg = np.mean(seen)\n",
        "                sd = np.std(seen)\n",
        "                top_n = int(round((20*i)/100))\n",
        "                topn_avg = np.mean(np.sort(seen)[top_n:])\n",
        "                bottomn_avg = np.mean(np.sort(seen)[:top_n+1])\n",
        "                diff = topn_avg - bottomn_avg\n",
        "                n_texts = (i-1)/(1999-1)\n",
        "            \n",
        "                x = np.array([n_texts,avg,sd,topn_avg,diff])\n",
        "                x_train.append(x)\n",
        "                y_train.append(di[sub_id][0])\n",
        "                \n",
        "    return np.array(x_train), np.array(y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zT9hOuTHHWEV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict_test_vectors(pred_dict, di, clf2):\n",
        "    \n",
        "    verdict_dict = {}\n",
        "    \n",
        "    for i in range(1,2000):\n",
        "        for sub_id in pred_dict:\n",
        "        \n",
        "            if i >= len(pred_dict[sub_id]):\n",
        "                verdict_dict[sub_id].append(verdict_dict[sub_id][-1])\n",
        "            else:\n",
        "                seen = np.array(pred_dict[sub_id][:i])\n",
        "                avg = np.mean(seen)\n",
        "                sd = np.std(seen)\n",
        "                top_n = int(round((20*i)/100))\n",
        "                topn_avg = np.mean(np.sort(seen)[top_n:])\n",
        "                bottomn_avg = np.mean(np.sort(seen)[:top_n+1])\n",
        "                diff = topn_avg - bottomn_avg\n",
        "                n_texts = (i-1)/(1999-1)\n",
        "\n",
        "                x = np.array([n_texts,avg,sd,topn_avg,diff])\n",
        "                x = x.reshape(1,-1)\n",
        "                verdict = clf2.predict(x)[0]\n",
        "\n",
        "                if sub_id in verdict_dict:\n",
        "                    verdict_dict[sub_id].append(verdict)\n",
        "                else:\n",
        "                    verdict_dict[sub_id] = [verdict]\n",
        "                \n",
        "    return verdict_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L7zFnpCuHbwD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluate(verdict_dict, o):\n",
        "    \n",
        "    # create dataframe to hold the data necessary for the final calculations\n",
        "    cols = [\"subject\", \"true_risk\", \"risk_decision\", \"delay\", \"erde\"]\n",
        "\n",
        "    df_final = pd.DataFrame(index = range(94),columns = cols)\n",
        "\n",
        "    count = 0\n",
        "    with open(\"/content/drive/My Drive/risk_test_users4.txt\", 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            df_final.iloc[count]['subject'] = line.split('\\t')[0].strip()\n",
        "            df_final.iloc[count]['true_risk'] = float(line.split('\\t')[1].strip())\n",
        "            count += 1\n",
        "\n",
        "\n",
        "    # here I put the risk_decision and delay in the dataframe  \n",
        "    for key in verdict_dict:\n",
        "        sub_row = df_final.index[df_final['subject'] == key].tolist()[0]\n",
        "\n",
        "        df_final.iloc[sub_row,2] = verdict_dict[key][-1]\n",
        "\n",
        "        if (df_final.iloc[sub_row,2] == 1) & (df_final.iloc[sub_row,1] == 1):\n",
        "            df_final.iloc[sub_row,3] = verdict_dict[key].index(1)\n",
        "\n",
        "    #extract the data\n",
        "    risk_d = df_final['risk_decision']\n",
        "    t_risk = df_final['true_risk']\n",
        "    k = df_final['delay']\n",
        "    erde = df_final['erde']\n",
        "\n",
        "    # Count of how many true positives there are\n",
        "    true_pos = len(df_final[t_risk==1])\n",
        "\n",
        "    # Count of how many positive cases the system decided there were\n",
        "    pos_decisions = len(df_final[risk_d==1])\n",
        "\n",
        "    # Count of how many of them are actually true positive cases\n",
        "    pos_hits = len(df_final[(t_risk==1) & (risk_d==1)])\n",
        "\n",
        "    # Total count of users\n",
        "    total_users = len(df_final)\n",
        "\n",
        "    # ERDE calculations\n",
        "    for i in range(total_users):\n",
        "        if(risk_d[i] == 1 and t_risk[i] == 0):\n",
        "            erde.iloc[i] = float(true_pos)/total_users\n",
        "        elif(risk_d[i] == 0 and t_risk[i] == 1):\n",
        "            erde.iloc[i] = 1.0\n",
        "        elif(risk_d[i] == 1 and t_risk[i] == 1):\n",
        "            erde.iloc[i] = 1.0 - (1.0/(1.0+np.exp(k[i]-o)))\n",
        "        elif(risk_d[i] == 0 and t_risk[i] == 0):\n",
        "            erde.iloc[i] = 0.0\n",
        "\n",
        "    # Calculation of F1, Precision, Recall and global ERDE\n",
        "    precision = float(pos_hits)/pos_decisions\n",
        "    recall = float(pos_hits)/true_pos\n",
        "    F1 = 2 * (precision * recall) / (precision + recall)\n",
        "    erde_global = erde.mean() * 100\n",
        "\n",
        "    #indiv_erde = df_final.iloc[:,['subject','erde']]\n",
        "    #print (indiv_erde.to_string())\n",
        "    print ('Global ERDE (with o = %d): %.2f' % (o, erde_global), '%')\n",
        "    print ('F1: %.2f' % F1)\n",
        "    print ('Precision: %.2f' % precision)\n",
        "    print ('Recall: %.2f' % recall)\n",
        "    return df_final"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bSDKTkWMHtrh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# read data, clean up texts and tokenize\n",
        "\n",
        "df_train, docs_train, Y_train = read_data('/content/drive/My Drive/training4.csv')\n",
        "df_test, docs_test, Y_test = read_data('/content/drive/My Drive/test4.csv')\n",
        "\n",
        "docs_train = docs_train.apply(cleanText)\n",
        "docs_test = docs_test.apply(cleanText)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GiCaqr_MILsy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# get vectors\n",
        "\n",
        "tokenizer = Tokenizer(num_words=10000)\n",
        "tokenizer.fit_on_texts(docs_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(docs_train)\n",
        "X_test = tokenizer.texts_to_sequences(docs_test)\n",
        "\n",
        "max_text_length = 100\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_text_length)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_text_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nDVMkZTsdmsl",
        "colab_type": "code",
        "outputId": "5807c21b-2a96-4a04-c8db-8ed466dc371e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "cell_type": "code",
      "source": [
        "# create Keras classifier with embedding layer\n",
        "\n",
        "embedding_dim = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(10000, embedding_dim, input_length=max_text_length))\n",
        "model.add(LSTM(100, return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 100, 100)          1000000   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100, 100)          80400     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100, 100)          0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 1,160,901\n",
            "Trainable params: 1,160,901\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NCwmCxLTedvK",
        "colab_type": "code",
        "outputId": "9bc65706-72d7-4f50-a7a1-3cb5e445944c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "cell_type": "code",
      "source": [
        "filepath=\"/content/drive/My Drive/Models/baseline_new_split.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint, EarlyStopping(monitor='val_loss',min_delta=0.0001)]\n",
        "model.fit(X_train, Y_train, validation_split=0.2, callbacks=callbacks_list, epochs=10, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 163076 samples, validate on 40770 samples\n",
            "Epoch 1/10\n",
            "163076/163076 [==============================] - 558s 3ms/step - loss: 0.2616 - acc: 0.9137 - val_loss: 0.2110 - val_acc: 0.9302\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.93022, saving model to /content/drive/My Drive/Models/baseline_new_split.hdf5\n",
            "Epoch 2/10\n",
            "163076/163076 [==============================] - 554s 3ms/step - loss: 0.2249 - acc: 0.9233 - val_loss: 0.2101 - val_acc: 0.9323\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.93022 to 0.93225, saving model to /content/drive/My Drive/Models/baseline_new_split.hdf5\n",
            "Epoch 3/10\n",
            "163076/163076 [==============================] - 552s 3ms/step - loss: 0.2041 - acc: 0.9298 - val_loss: 0.2251 - val_acc: 0.9256\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.93225\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3147a9ec18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "4xAYkcNyJNVO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "e0286d88-1e0e-4c7c-9476-7de2e5559c60"
      },
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model('/content/drive/My Drive/Models/baseline_new_split.hdf5')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VWmozZIsB76p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pred = model.predict_classes(X_test)\n",
        "indices = [i for i,v in enumerate(pred) if pred[i]!=Y_test[i]]\n",
        "#subset_of_wrongly_predicted = [X_test[i] for i in indices ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fM1LwQQDCwdA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "wrong_texts = [docs_test.iloc[i] for i in indices]\n",
        "correct_y = [Y_test[i] for i in indices]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uQBtB_nxFQ5e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "s1 = pd.Series(wrong_texts, name='document')\n",
        "s2 = pd.Series(correct_y, name='correct label')\n",
        "\n",
        "wrong_df = pd.concat([s1, s2], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xa0hMnIwFq5e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "wrong_df.to_csv('/content/drive/My Drive/errors_baseline.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XJzAChCscF9C",
        "colab_type": "code",
        "outputId": "af0ed006-dfe4-42bc-865b-ab12ef22e4bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(X_test, Y_test, verbose=1)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "49374/49374 [==============================] - 296s 6ms/sample - loss: 0.2957 - acc: 0.9175\n",
            "Accuracy: 91.75%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6ZwyOg1OIOzQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# sort texts by date and make predictions for both training and test set\n",
        "df_train['Text'] = df_train['Text'].apply(cleanText)\n",
        "df_test['Text'] = df_test['Text'].apply(cleanText)\n",
        "\n",
        "dict_train = sort_by_date(df_train)\n",
        "dict_test = sort_by_date(df_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1L6E609dY2H0",
        "colab_type": "code",
        "outputId": "e9c88577-67bb-4cad-91a4-d172320aea75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "pred_dict_train = predict_texts(dict_train, model, tokenizer)\n",
        "pred_dict_test = predict_texts(dict_test, model, tokenizer)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting prediction...\n",
            "Prediction done!\n",
            "Starting prediction...\n",
            "Prediction done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QjNHjPY2IR8z",
        "colab_type": "code",
        "outputId": "5eac3ac4-6fdd-40fc-9070-00788b3ea9c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "# get the feature vectors and train the person classifier\n",
        "\n",
        "x_train, y_train = create_train_vectors(pred_dict_train, dict_train)\n",
        "\n",
        "clf = MLPClassifier(alpha=1e-5, hidden_layer_sizes=(10,2))\n",
        "clf.fit(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
              "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "       hidden_layer_sizes=(10, 2), learning_rate='constant',\n",
              "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
              "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
              "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
              "       validation_fraction=0.1, verbose=False, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "CtJqVMSJIU7g",
        "colab_type": "code",
        "outputId": "6dc6c75e-00d4-4f12-9846-51672276199c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "x_test, y_test = create_train_vectors(pred_dict_test, dict_test)\n",
        "clf.score(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9115462662337662"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "aBlBVoWikYK3",
        "colab_type": "code",
        "outputId": "d8d99692-3a01-4459-ab61-f0850f338024",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "clf2 = LogisticRegression(max_iter=2000, class_weight = 'balanced',solver='saga')\n",
        "clf2.fit(x_train, y_train)\n",
        "clf2.score(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9199878246753247"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "9Y1TLH55IYA6",
        "colab_type": "code",
        "outputId": "cf9435b2-2033-4e22-c554-d77aa3a81ea1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "# predict test set and evaluate\n",
        "\n",
        "verdict_dict = predict_test_vectors(pred_dict_test, dict_test, clf2)\n",
        "df_final = evaluate(verdict_dict, 50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Global ERDE (with o = 50): 2.40 %\n",
            "F1: 0.83\n",
            "Precision: 0.83\n",
            "Recall: 0.83\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s5uu0qK4Ia29",
        "colab_type": "code",
        "outputId": "b2464315-ede2-4e4f-9885-bd3f3f7d0e1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1969
        }
      },
      "cell_type": "code",
      "source": [
        "df_final"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subject</th>\n",
              "      <th>true_risk</th>\n",
              "      <th>risk_decision</th>\n",
              "      <th>delay</th>\n",
              "      <th>erde</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>subject9225</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>subject5562</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>subject5469</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>subject4588</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>subject5241</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>subject489</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>subject9654</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>subject3039</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>subject4999</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>subject803</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>subject2513</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>subject8657</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00669285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>subject7066</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>subject5802</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>subject6412</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>subject4061</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>subject828</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>subject5325</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>subject2746</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>subject6921</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.159574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>subject9334</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>subject5517</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>subject8740</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00669285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>subject8173</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>subject6292</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>subject3359</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>subject1604</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>subject8054</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>subject5155</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>subject6731</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>subject4450</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>subject901</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>subject8053</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>subject1496</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>subject2845</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0179862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>subject6792</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>subject3278</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>subject2062</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>subject845</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>0.999665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>subject2519</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>subject2662</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>subject7249</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>subject4482</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>subject2879</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>subject1369</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>subject9003</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0179862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>subject5127</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>subject6114</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>subject4592</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>subject6639</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>0.982014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>subject3530</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>subject5221</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>subject1913</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00669285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>subject2777</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>subject9981</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>subject531</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>subject5954</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>subject4556</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>subject1272</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>subject8296</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>94 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        subject true_risk risk_decision delay        erde\n",
              "0   subject9225         0             0   NaN           0\n",
              "1   subject5562         0             0   NaN           0\n",
              "2   subject5469         0             0   NaN           0\n",
              "3   subject4588         0             0   NaN           0\n",
              "4   subject5241         0             0   NaN           0\n",
              "5    subject489         0             0   NaN           0\n",
              "6   subject9654         0             0   NaN           0\n",
              "7   subject3039         0             0   NaN           0\n",
              "8   subject4999         0             0   NaN           0\n",
              "9    subject803         0             0   NaN           0\n",
              "10  subject2513         0             0   NaN           0\n",
              "11  subject8657         1             1     0  0.00669285\n",
              "12  subject7066         0             0   NaN           0\n",
              "13  subject5802         0             0   NaN           0\n",
              "14  subject6412         0             0   NaN           0\n",
              "15  subject4061         0             0   NaN           0\n",
              "16   subject828         0             0   NaN           0\n",
              "17  subject5325         0             0   NaN           0\n",
              "18  subject2746         0             0   NaN           0\n",
              "19  subject6921         0             1   NaN    0.159574\n",
              "20  subject9334         0             0   NaN           0\n",
              "21  subject5517         1             1     5         0.5\n",
              "22  subject8740         1             1     0  0.00669285\n",
              "23  subject8173         0             0   NaN           0\n",
              "24  subject6292         0             0   NaN           0\n",
              "25  subject3359         0             0   NaN           0\n",
              "26  subject1604         0             0   NaN           0\n",
              "27  subject8054         0             0   NaN           0\n",
              "28  subject5155         0             0   NaN           0\n",
              "29  subject6731         0             0   NaN           0\n",
              "..          ...       ...           ...   ...         ...\n",
              "64  subject4450         0             0   NaN           0\n",
              "65   subject901         0             0   NaN           0\n",
              "66  subject8053         0             0   NaN           0\n",
              "67  subject1496         0             0   NaN           0\n",
              "68  subject2845         1             1     1   0.0179862\n",
              "69  subject6792         0             0   NaN           0\n",
              "70  subject3278         0             0   NaN           0\n",
              "71  subject2062         1             0   NaN           1\n",
              "72   subject845         1             1    13    0.999665\n",
              "73  subject2519         0             0   NaN           0\n",
              "74  subject2662         0             0   NaN           0\n",
              "75  subject7249         0             0   NaN           0\n",
              "76  subject4482         0             0   NaN           0\n",
              "77  subject2879         0             0   NaN           0\n",
              "78  subject1369         0             0   NaN           0\n",
              "79  subject9003         1             1     1   0.0179862\n",
              "80  subject5127         1             1    20           1\n",
              "81  subject6114         0             0   NaN           0\n",
              "82  subject4592         0             0   NaN           0\n",
              "83  subject6639         1             1     9    0.982014\n",
              "84  subject3530         0             0   NaN           0\n",
              "85  subject5221         0             0   NaN           0\n",
              "86  subject1913         1             1     0  0.00669285\n",
              "87  subject2777         0             0   NaN           0\n",
              "88  subject9981         0             0   NaN           0\n",
              "89   subject531         0             0   NaN           0\n",
              "90  subject5954         0             0   NaN           0\n",
              "91  subject4556         0             0   NaN           0\n",
              "92  subject1272         0             0   NaN           0\n",
              "93  subject8296         0             0   NaN           0\n",
              "\n",
              "[94 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    }
  ]
}