{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GloVe.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nuccy90/Master_thesis/blob/master/GloVe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "tSfnXhMPGqU-",
        "colab_type": "code",
        "outputId": "5891d9d0-fcc8-466c-b556-75c4cbc35815",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import itertools\n",
        "import io\n",
        "import nltk\n",
        "import pickle\n",
        "from tensorflow import keras\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dropout, Dense\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "zatLzk6LbDwB",
        "colab_type": "code",
        "outputId": "59ce26bc-99b1-4ca6-9cde-15d74df5a502",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "2f395b9d-e711-4fac-ee41-97a0a11316d5",
        "id": "h9mGeE6rs6Lq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "M8jL3EpfGxq7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def read_data(name):\n",
        "    \n",
        "    df = pd.read_csv(name)\n",
        "    df['Text'] = df['Text'].fillna(\"  \")\n",
        "    df['Title'] = df['Title'].fillna(\"  \")\n",
        "    df = df[(df[\"Text\"] != \"  \") | (df[\"Title\"]!= \"  \")]\n",
        "    docs = df['Title'] + df['Text']\n",
        "    Y = df[\"Diagnosis\"].values\n",
        "    \n",
        "    return df, docs, Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B_8oJlSNG-9f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cleanText(text):\n",
        "    \n",
        "    sw = stopwords.words('english')[35:]\n",
        "    text = re.sub(r'\\|\\|\\|', r' ', text) \n",
        "    text = re.sub(r'http\\S+', r'<URL>', text)\n",
        "    text = re.sub(r'\\d{6,}', r'<NUM>', text)\n",
        "    text = text.lower()\n",
        "    text = ' '.join(word for word in text.split() if not word in sw)\n",
        "    \n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C4OqQyEbXasK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_embed_mat(glove_file, max_features, tokenizer):\n",
        "    \n",
        "    def get_coefs(word,*arr): \n",
        "        return word, np.asarray(arr, dtype='float32')\n",
        "    \n",
        "    embed_dim = 200\n",
        "    \n",
        "    # word vectors\n",
        "    embeddings_index = dict(get_coefs(*s.rstrip().rsplit(' ')) for s in open(glove_file, encoding='utf8'))\n",
        "    print('Found %s word vectors.' % len(embeddings_index))\n",
        "\n",
        "    # embedding matrix\n",
        "    word_index = tokenizer.word_index\n",
        "    num_words = min(max_features, len(word_index) + 1)\n",
        "    all_embs = np.stack(embeddings_index.values()) #for random init\n",
        "    embedding_matrix = np.random.normal(all_embs.mean(), all_embs.std(), \n",
        "                                        (num_words, embed_dim))\n",
        "    for word, i in word_index.items():\n",
        "        if i >= max_features:\n",
        "            continue\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "    max_features = embedding_matrix.shape[0]\n",
        "    \n",
        "    return embedding_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ox0vG4iZHDiT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sort_by_date(df):\n",
        "\n",
        "    di = {}        \n",
        "    for index, row in df.iterrows():\n",
        "\n",
        "        sub_id = row[\"Subject\"]\n",
        "        diagnosis = row[\"Diagnosis\"]\n",
        "        if sub_id in di:\n",
        "            di[sub_id][1].append(row[\"Text\"]+row[\"Title\"])\n",
        "            di[sub_id][2].append(row[\"Date\"])\n",
        "        else:\n",
        "            di[sub_id] = [diagnosis,[row[\"Text\"]+row[\"Title\"]], [row[\"Date\"]]]\n",
        "\n",
        "    for key in di:\n",
        "        list_of_datetimes = [datetime.strptime(x, ' %Y-%m-%d %H:%M:%S ') for x in di[key][2]]\n",
        "\n",
        "        lists = sorted(zip(*[list_of_datetimes, di[key][1]]))\n",
        "        dates, texts = list(zip(*lists))\n",
        "\n",
        "        di[key][1] = texts\n",
        "        di[key][2] = dates\n",
        "        \n",
        "    return di"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wNHZRTHgHJy0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict_texts(di, model, tokenizer):\n",
        "    print(\"Starting prediction...\")\n",
        "    pred_dict = {}\n",
        "    \n",
        "    def predict_scores(sub_id, texts, model = model, tokenizer = tokenizer, pred_dict = pred_dict):\n",
        "    \n",
        "        #add score to dictionary\n",
        "        x_texts = tokenizer.texts_to_sequences(texts)\n",
        "        x_texts = sequence.pad_sequences(x_texts, maxlen=100)\n",
        "        scores = model.predict(x_texts)\n",
        "        pred_dict[sub_id] = scores\n",
        "            \n",
        "        return pred_dict\n",
        "    \n",
        "    for sub_id in di:\n",
        "        texts = di[sub_id][1]\n",
        "        pred_dict = predict_scores(sub_id, texts)\n",
        "    \n",
        "    print(\"Prediction done!\")\n",
        "    return pred_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1Xy7-0jJHO7x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_train_vectors(pred_dict, di):\n",
        "    \n",
        "    x_train = []\n",
        "    y_train = []\n",
        "\n",
        "    for i in range(1,2000):\n",
        "        for sub_id in pred_dict:\n",
        "        \n",
        "            if i >= len(pred_dict[sub_id]):\n",
        "                pass\n",
        "            else:\n",
        "                seen = pred_dict[sub_id][:i]\n",
        "                avg = np.mean(seen)\n",
        "                sd = np.std(seen)\n",
        "                top_n = int(round((20*i)/100))\n",
        "                topn_avg = np.mean(np.sort(seen)[top_n:])\n",
        "                bottomn_avg = np.mean(np.sort(seen)[:top_n+1])\n",
        "                diff = topn_avg - bottomn_avg\n",
        "                n_texts = (i-1)/(1999-1)\n",
        "            \n",
        "                x = np.array([n_texts,avg,sd,topn_avg,diff])\n",
        "                x_train.append(x)\n",
        "                y_train.append(di[sub_id][0])\n",
        "                \n",
        "    return np.array(x_train), np.array(y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zT9hOuTHHWEV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict_test_vectors(pred_dict, di, clf2):\n",
        "    \n",
        "    verdict_dict = {}\n",
        "    \n",
        "    for i in range(1,2000):\n",
        "        for sub_id in pred_dict:\n",
        "        \n",
        "            if i >= len(pred_dict[sub_id]):\n",
        "                verdict_dict[sub_id].append(verdict_dict[sub_id][-1])\n",
        "            else:\n",
        "                seen = np.array(pred_dict[sub_id][:i])\n",
        "                avg = np.mean(seen)\n",
        "                sd = np.std(seen)\n",
        "                top_n = int(round((20*i)/100))\n",
        "                topn_avg = np.mean(np.sort(seen)[top_n:])\n",
        "                bottomn_avg = np.mean(np.sort(seen)[:top_n+1])\n",
        "                diff = topn_avg - bottomn_avg\n",
        "                n_texts = (i-1)/(1999-1)\n",
        "\n",
        "                x = np.array([n_texts,avg,sd,topn_avg,diff])\n",
        "                x = x.reshape(1,-1)\n",
        "                verdict = clf2.predict(x)[0]\n",
        "\n",
        "                if sub_id in verdict_dict:\n",
        "                    verdict_dict[sub_id].append(verdict)\n",
        "                else:\n",
        "                    verdict_dict[sub_id] = [verdict]\n",
        "                \n",
        "    return verdict_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L7zFnpCuHbwD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluate(verdict_dict, o):\n",
        "    \n",
        "    # create dataframe to hold the data necessary for the final calculations\n",
        "    cols = [\"subject\", \"true_risk\", \"risk_decision\", \"delay\", \"erde\"]\n",
        "\n",
        "    df_final = pd.DataFrame(index = range(94),columns = cols)\n",
        "\n",
        "    count = 0\n",
        "    with open(\"/content/drive/My Drive/risk_test_users.txt\", 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            df_final.iloc[count]['subject'] = line.split('\\t')[0].strip()\n",
        "            df_final.iloc[count]['true_risk'] = float(line.split('\\t')[1].strip())\n",
        "            count += 1\n",
        "\n",
        "\n",
        "    # here i put the risk_decision and delay in the dataframe  \n",
        "    for key in verdict_dict:\n",
        "        sub_row = df_final.index[df_final['subject'] == key].tolist()[0]\n",
        "\n",
        "        df_final.iloc[sub_row,2] = verdict_dict[key][-1]\n",
        "\n",
        "        if (df_final.iloc[sub_row,2] == 1) & (df_final.iloc[sub_row,1] == 1):\n",
        "            df_final.iloc[sub_row,3] = verdict_dict[key].index(1)\n",
        "\n",
        "    #extract the data\n",
        "    risk_d = df_final['risk_decision']\n",
        "    t_risk = df_final['true_risk']\n",
        "    k = df_final['delay']\n",
        "    erde = df_final['erde']\n",
        "\n",
        "    # Count of how many true positives there are\n",
        "    true_pos = len(df_final[t_risk==1])\n",
        "\n",
        "    # Count of how many positive cases the system decided there were\n",
        "    pos_decisions = len(df_final[risk_d==1])\n",
        "\n",
        "    # Count of how many of them are actually true positive cases\n",
        "    pos_hits = len(df_final[(t_risk==1) & (risk_d==1)])\n",
        "\n",
        "    # Total count of users\n",
        "    total_users = len(df_final)\n",
        "\n",
        "    # ERDE calculations\n",
        "    for i in range(total_users):\n",
        "        if(risk_d[i] == 1 and t_risk[i] == 0):\n",
        "            erde.iloc[i] = float(true_pos)/total_users\n",
        "        elif(risk_d[i] == 0 and t_risk[i] == 1):\n",
        "            erde.iloc[i] = 1.0\n",
        "        elif(risk_d[i] == 1 and t_risk[i] == 1):\n",
        "            erde.iloc[i] = 1.0 - (1.0/(1.0+np.exp(k[i]-o)))\n",
        "        elif(risk_d[i] == 0 and t_risk[i] == 0):\n",
        "            erde.iloc[i] = 0.0\n",
        "\n",
        "    # Calculation of F1, Precision, Recall and global ERDE\n",
        "    precision = float(pos_hits)/pos_decisions\n",
        "    recall = float(pos_hits)/true_pos\n",
        "    F1 = 2 * (precision * recall) / (precision + recall)\n",
        "    erde_global = erde.mean() * 100\n",
        "\n",
        "    #indiv_erde = df_final.iloc[:,['subject','erde']]\n",
        "    #print (indiv_erde.to_string())\n",
        "    print ('Global ERDE (with o = %d): %.2f' % (o, erde_global), '%')\n",
        "    print ('F1: %.2f' % F1)\n",
        "    print ('Precision: %.2f' % precision)\n",
        "    print ('Recall: %.2f' % recall)\n",
        "    return df_final"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bSDKTkWMHtrh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# read data, clean up texts and tokenize\n",
        "\n",
        "df_train, docs_train, Y_train = read_data('/content/drive/My Drive/training.csv')\n",
        "df_test, docs_test, Y_test = read_data('/content/drive/My Drive/test.csv')\n",
        "\n",
        "docs_train = docs_train.apply(cleanText)\n",
        "docs_test = docs_test.apply(cleanText)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GiCaqr_MILsy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# get vectors\n",
        "\n",
        "tokenizer = Tokenizer(num_words=10000)\n",
        "tokenizer.fit_on_texts(docs_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(docs_train)\n",
        "X_test = tokenizer.texts_to_sequences(docs_test)\n",
        "\n",
        "max_text_length = 100\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_text_length)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_text_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nc_lD_Dgu1pN",
        "colab_type": "code",
        "outputId": "48c13d94-150a-45ac-e762-61558bced906",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "glove_file = \"/content/drive/My Drive/glove.twitter.27B.200d.txt\"\n",
        "max_features = 10000\n",
        "embedding_matrix = get_embed_mat(glove_file, max_features, tokenizer)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1193514 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nDVMkZTsdmsl",
        "colab_type": "code",
        "outputId": "86b9e5bb-8ff7-490f-81fa-3063a04beb10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "cell_type": "code",
      "source": [
        "# create Keras classifier with embedding layer\n",
        "\n",
        "embedding_dim = 200\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(10000, embedding_dim, input_length=max_text_length, \n",
        "                    weights=[embedding_matrix], trainable=False))\n",
        "model.add(LSTM(100, return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 100, 200)          2000000   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100, 100)          120400    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100, 100)          0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 2,200,901\n",
            "Trainable params: 200,901\n",
            "Non-trainable params: 2,000,000\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NCwmCxLTedvK",
        "colab_type": "code",
        "outputId": "39bb46eb-2528-43c2-d6e2-e8bae308228b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "cell_type": "code",
      "source": [
        "filepath=\"/content/drive/My Drive/Models/glove_new_split.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint, EarlyStopping(monitor='val_loss',min_delta=0.0001)]\n",
        "model.fit(X_train, Y_train, validation_split=0.2, callbacks=callbacks_list, epochs=10, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 163076 samples, validate on 40770 samples\n",
            "Epoch 1/10\n",
            "163076/163076 [==============================] - 543s 3ms/step - loss: 0.2709 - acc: 0.9088 - val_loss: 0.2266 - val_acc: 0.9288\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.92882, saving model to /content/drive/My Drive/Models/glove_new_split.hdf5\n",
            "Epoch 2/10\n",
            "163076/163076 [==============================] - 541s 3ms/step - loss: 0.2534 - acc: 0.9139 - val_loss: 0.2140 - val_acc: 0.9298\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.92882 to 0.92978, saving model to /content/drive/My Drive/Models/glove_new_split.hdf5\n",
            "Epoch 3/10\n",
            "163076/163076 [==============================] - 537s 3ms/step - loss: 0.2436 - acc: 0.9170 - val_loss: 0.2118 - val_acc: 0.9299\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.92978 to 0.92987, saving model to /content/drive/My Drive/Models/glove_new_split.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1292e996d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "4xAYkcNyJNVO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model('/content/drive/My Drive/Models/glove_new_split.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XJzAChCscF9C",
        "colab_type": "code",
        "outputId": "612d183d-65b2-435b-cba8-c4b4b74e3a7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(X_test, Y_test, verbose=1)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "49374/49374 [==============================] - 304s 6ms/sample - loss: 0.2940 - acc: 0.9139\n",
            "Accuracy: 91.39%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6ZwyOg1OIOzQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# sort texts by date and make predictions for both training and test set\n",
        "df_train['Text'] = df_train['Text'].apply(cleanText)\n",
        "df_test['Text'] = df_test['Text'].apply(cleanText)\n",
        "\n",
        "dict_train = sort_by_date(df_train)\n",
        "dict_test = sort_by_date(df_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1L6E609dY2H0",
        "colab_type": "code",
        "outputId": "d92ec50e-69b8-4dda-8455-b7160fb55348",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "pred_dict_train = predict_texts(dict_train, model, tokenizer)\n",
        "pred_dict_test = predict_texts(dict_test, model, tokenizer)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting prediction...\n",
            "Prediction done!\n",
            "Starting prediction...\n",
            "Prediction done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "W34ffZGXdaIo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train, y_train = create_train_vectors(pred_dict_train, dict_train)\n",
        "x_test, y_test = create_train_vectors(pred_dict_test, dict_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tAm1KbDLWIgT",
        "colab_type": "code",
        "outputId": "51e17d72-bd56-40a6-f871-5db117b8442b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "clf = MLPClassifier(alpha=1e-5, hidden_layer_sizes=(10,2))\n",
        "clf.fit(x_train, y_train)\n",
        "\n",
        "#pickle.dump(clf, open('/content/drive/My Drive/Models/clf_glove_new_split.sav', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
              "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "       hidden_layer_sizes=(10, 2), learning_rate='constant',\n",
              "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
              "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
              "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
              "       validation_fraction=0.1, verbose=False, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "metadata": {
        "id": "0wuzz4rKZLQV",
        "colab_type": "code",
        "outputId": "ac5cbefa-5407-42c3-f8d8-d86a9ab02e1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf.score(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9308847402597402"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "id": "7rHbRkwjyWEq",
        "colab_type": "code",
        "outputId": "44445aef-9282-4f2c-91ea-def5194bba20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "clf2 = LogisticRegression(max_iter=2000, class_weight = 'balanced',solver='saga')\n",
        "clf2.fit(x_train, y_train)\n",
        "clf2.score(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8501826298701298"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "9Y1TLH55IYA6",
        "colab_type": "code",
        "outputId": "95b9fd14-3ec1-41b7-db4d-56145d72dc12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "# predict test set and evaluate\n",
        "\n",
        "verdict_dict = predict_test_vectors(pred_dict_test, dict_test, clf)\n",
        "df_final = evaluate(verdict_dict, 5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Global ERDE (with o = 5): 8.71 %\n",
            "F1: 0.86\n",
            "Precision: 1.00\n",
            "Recall: 0.75\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s5uu0qK4Ia29",
        "colab_type": "code",
        "outputId": "5076da48-46fc-4c4b-bdef-2e6cc8365d31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1969
        }
      },
      "cell_type": "code",
      "source": [
        "df_final"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subject</th>\n",
              "      <th>true_risk</th>\n",
              "      <th>risk_decision</th>\n",
              "      <th>delay</th>\n",
              "      <th>erde</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>subject8411</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>subject626</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>subject6670</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>subject5220</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>subject2359</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>subject6333</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>subject5469</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>subject5241</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>subject31</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>subject1152</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>0.993307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>subject4999</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>subject5426</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>subject4073</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>subject4061</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>subject2728</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>subject828</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>subject5325</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>subject5067</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>subject1773</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0.731059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>subject3094</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0.952574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>subject1565</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>subject6088</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>subject5452</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>subject3504</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>subject811</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>subject3339</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>subject3359</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>subject3859</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>subject8054</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>subject3788</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>subject6462</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>subject9436</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>subject6139</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>subject3274</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>subject8512</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>subject4153</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>subject1120</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>subject2845</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0179862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>subject6792</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>subject3278</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>subject845</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>subject545</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>subject7249</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>subject1417</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>subject6892</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>subject8167</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>subject7442</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>subject4592</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>subject6414</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>subject6807</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>subject3750</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>subject1913</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>0.999998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>subject5830</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>subject5177</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>subject9981</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>subject531</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>subject6269</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>subject8401</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>subject3727</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>subject366</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>94 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        subject true_risk risk_decision delay       erde\n",
              "0   subject8411         1             0   NaN          1\n",
              "1    subject626         0             0   NaN          0\n",
              "2   subject6670         0             0   NaN          0\n",
              "3   subject5220         0             0   NaN          0\n",
              "4   subject2359         0             0   NaN          0\n",
              "5   subject6333         0             0   NaN          0\n",
              "6   subject5469         0             0   NaN          0\n",
              "7   subject5241         0             0   NaN          0\n",
              "8     subject31         0             0   NaN          0\n",
              "9   subject1152         1             1    10   0.993307\n",
              "10  subject4999         0             0   NaN          0\n",
              "11  subject5426         0             0   NaN          0\n",
              "12  subject4073         0             0   NaN          0\n",
              "13  subject4061         0             0   NaN          0\n",
              "14  subject2728         0             0   NaN          0\n",
              "15   subject828         0             0   NaN          0\n",
              "16  subject5325         0             0   NaN          0\n",
              "17  subject5067         0             0   NaN          0\n",
              "18  subject1773         1             1     6   0.731059\n",
              "19  subject3094         1             1     8   0.952574\n",
              "20  subject1565         0             0   NaN          0\n",
              "21  subject6088         0             0   NaN          0\n",
              "22  subject5452         0             0   NaN          0\n",
              "23  subject3504         0             0   NaN          0\n",
              "24   subject811         0             0   NaN          0\n",
              "25  subject3339         0             0   NaN          0\n",
              "26  subject3359         0             0   NaN          0\n",
              "27  subject3859         0             0   NaN          0\n",
              "28  subject8054         0             0   NaN          0\n",
              "29  subject3788         0             0   NaN          0\n",
              "..          ...       ...           ...   ...        ...\n",
              "64  subject6462         1             1     5        0.5\n",
              "65  subject9436         0             0   NaN          0\n",
              "66  subject6139         0             0   NaN          0\n",
              "67  subject3274         0             0   NaN          0\n",
              "68  subject8512         0             0   NaN          0\n",
              "69  subject4153         0             0   NaN          0\n",
              "70  subject1120         0             0   NaN          0\n",
              "71  subject2845         1             1     1  0.0179862\n",
              "72  subject6792         0             0   NaN          0\n",
              "73  subject3278         0             0   NaN          0\n",
              "74   subject845         1             0   NaN          1\n",
              "75   subject545         0             0   NaN          0\n",
              "76  subject7249         0             0   NaN          0\n",
              "77  subject1417         0             0   NaN          0\n",
              "78  subject6892         0             0   NaN          0\n",
              "79  subject8167         0             0   NaN          0\n",
              "80  subject7442         0             0   NaN          0\n",
              "81  subject4592         0             0   NaN          0\n",
              "82  subject6414         0             0   NaN          0\n",
              "83  subject6807         0             0   NaN          0\n",
              "84  subject3750         0             0   NaN          0\n",
              "85  subject1913         1             1    18   0.999998\n",
              "86  subject5830         0             0   NaN          0\n",
              "87  subject5177         0             0   NaN          0\n",
              "88  subject9981         0             0   NaN          0\n",
              "89   subject531         0             0   NaN          0\n",
              "90  subject6269         0             0   NaN          0\n",
              "91  subject8401         0             0   NaN          0\n",
              "92  subject3727         0             0   NaN          0\n",
              "93   subject366         0             0   NaN          0\n",
              "\n",
              "[94 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "metadata": {
        "id": "qDJ-AdjQVV4X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}